 <!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
    text-align: "middle";
  }
  h1 {
    font-size: 20px;
  }
  h2 {
    font-size: 18px;
  }
  h3 {
    font-size: 16px;
  }
  h4 {
    font-size: 14px;
  }
  #container {
    width: 100%;
    height: 500px;
  }
  p {
    font-size: 14px;
  }
</style>
<title>CS 184 Mesh Editor</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

</head>

<body>
<h3 align="middle">Berkeley CS184/284A - Spring 2018</h3>
<h1 align="middle">Final Project Report</h1>
<h1 align="middle">Real-time 2D Global Illumination</h1>
<br/>
<h3 align="middle">Joseph Moon (3033156362), Abdul AlZanki (25740621), Lawrence Elkins (23452545)</h3>
<br/>

<div align="middle">
  <a href="index.html"><font size="3">Go back</font></a>
</div>

<br/>

<div align="left">
  <div align="middle"><h1>Abstract</h1></div>
  <p>Real-time global illumination remains an unsolved problem in high-fidelity graphics. Traditional raytracing (i.e. pathtracing) casts rays from the camera into the scene. This becomes prohibitively expensive as the number of ray bounces grows. Dependencies between rays and the high cost of testing intersections also make raytracing difficult to parallelize on a GPU. Photon mapping, which casts rays from light sources, faces the same problem. We attempt to resolve these problems in a 2D web application using shader-based radiosity with parallel ray-bundling. This algorithm can utilize the GPU more effectively by casting rays in parallel bundles. By calculating all potential intersections in a single render pass, we hoped it would be possible to achieve real-time 2D global illumination. However, we eventually discovered that our chosen platform, WebGL, presented intractable technical barriers to indirect lighting and high-fidelity real-time performance. Nevertheless, this project served as a valuable exploration of shader programming.</p>

  <div align="middle"><h1>Technical Approach</h1></div>
  <div align="middle"><h2>Background</h2></div>
  <p>One of the main problems with Monte Carlo rendering is that similar rays become scattered and incoherent after first colliding with the scene, limiting its ability to parallelize on the GPU. Mortensen, Khanna, and Slater first proposed an atlas-based representation of a scene's light field to achieve global illumination [Mortensen, Khanna, Slater 2007]. After casting parallel rays into the scene from many different angles and storing intersections in a texture atlas, one can calculate irradiance at a location with a fast recursive lookup.</p>

  <div align="middle">
    <table style="width=100%">
      <tr>
        <td>
          <img src="images/parallel_ray_bundling.png" align="middle" width="300px"/>
          <figcaption align="middle"><font size="2">Instead of raycasting randomly from different positions, we use bundles of parallel rays.</font></figcaption>
        </td>
        <td>
          <img src="images/parallel_ray_bundling2.png" align="middle" width="300px"/>
          <figcaption align="middle"><font size="2">Radiance is passed between intersection points.</font></figcaption>
        </td>
        <td>
          <img src="images/parallel_ray_bounce.png" align="middle" width="300px"/>
          <figcaption align="middle"><font size="2">Similar to traditional raytracing, we calculate bounces recursively.</font></figcaption>
        </td>
      </tr>
    </table>
  </div>

   <p>To speed up this technique, Hermes et al. proposed using the GPU's depth-buffer to sort intersections [Hermes et al. 2010]. While this approach could reduce in-production render times for 3D scenes to a matter of hours, a 2D implementation by Thomas Diewald claimed to achieve real-time performance on commodity hardware (unfortunately without any documentation or released software). However, all implementations using the GPU depth-buffer algorithm rely on a feature - atomic counters - which has been compromised by the Spectre vulnerability. While it is still possible to create desktop OpenGL applications using atomic counters, all major web browsers now prohibit atomic WebGL calls. We saw an opportunity to implement parallel ray-bundling without this software vulnerability, by using the atlas-based representation first proposed by Mortensen et al.</p>

  <div align="middle"><h2>Implementation</h2></div>

  <p>We initially attempted to calculate intersection points by raymarching across a signed distance field. However, we found that blind raymarching could not find intersections beyond the first, since the distance becomes stuck at zero. Due to the prohibitive cost of conditional branches in shaders, it was not possible to remove those meshes which the ray had already intersected.</p>

  <p>To reach real-time performance, our algorithm must break down into small, parallel tasks that can be written into shader programs that run on the GPU. However, the GPU must also read in scene objects every frame (since defining objects entirely in the shader would limit interactivity). Therefore we use Three.js meshes as our scene objects and calculate lighting solutions based on their current size and position.

  <h3>Collecting Mesh Information</h3>
  <p>To read mesh information into the shader, we tried recompiling the shader every frame, encoding mesh information as a sampling texture, and passing each mesh into the shader as individual uniforms. These were either too slow or limited by hardware constraints. However, by using a feature newly introduced in WebGL2 - uniform buffer objects - we may be able to send to the GPU thousands of bytes containing uniform data.</p>

  <h3>Calculating Parallel Ray Intersections</h3>
  <p>The first shader in our render pipeline, the intersection shader outputs a fixed-size texture containing carefully encoded data. We define the x-axis as the index of the parallel offset. This means that horizontally adjacent pixels correspond to adjacent rays, with x=0 being the right-most ray and x=isectWidth being the left-most ray (relative to whichever angle they were cast from). We divided the y-axis into chunks for each angle, with the height of each chunk being the maximum number of intersections each ray can record. The R, G, and B color values of each pixel contain each intersection's meshId and distance along the ray. This lets us quickly determine how far away it is from a point on the same ray and which mesh to lookup for lighting information.</p>

  <div align="middle">
    <table style="width=100%" cellpadding="32">
      <tr>
        <td align="middle">
          <img src="images/isect_buffer.jpg" align="middle" height="200px"/>
          <figcaption align="middle"><font size="2">Structure of the intersect buffer</font></figcaption>
        </td>
        <td align="middle">
          <img src="images/isect_buffer_real.png" align="middle" height="200px"/>
          <figcaption align="middle"><font size="2">Example of the entire intersect buffer</font></figcaption>
        </td>
      </tr>
    </table>
  </div>

  <p>Observe that the intersect buffer has a horizontal striped pattern. This is because parallel rays tend to have similar intersection depths until they enter or exit a mesh. Indeed, we see each mesh forms a vertical pattern, because rays from many angles hit them at gradually differing offsets.</p>

  <h3>Calculating Light For Each Bounce (Not Yet Implemented)</h3>
  <p>Once we have calculated the intersection of those rays with all of the meshes and stored it in our intersect buffer, we are able calculate the radiance for all of the scene and reflect that on the lights and shadows shown on the ground. For each pixel, we iterate through each angle. In each angle, we determine the ray passing through that pixel and find the two closest intersections (if they exist). If either of these intersections corresponds to a light-emitting mesh, we calculate the resulting irradiance at the pixel relative to its distance from the intersection. We add together all the irradiances and divide the sum by the number of angles. This should give us direct lighting.</p>

  <p>For indirect lighting, we can use the same algorithm on the intersection points themselves, finding which rays emit onto them. This will probably be a separate render pass, so as to avoid dependency issues between bounces.</p>

  <br/>
<!--  <div align="middle">
      <table style="width=100%">
        <tr>
          <td>
            <img src="images/parallel_rays.jpg" align="middle" width="200px"/>
          </td>
        </tr>
      </table>
    </div>
    <br/>
  </div>
  <div align="middle"><p><font size="2">For each angle, pixels will gather light from the nearest intersections along the same ray</font></p></div>
 -->
    
<!--   <p>
    Latex examples:<br/>
    \(ax^2 + bx + c = 0\)
    <br/>
    $$x = {-b \pm \sqrt{b^2-4ac} \over 2a}.$$
  </p> -->

  <div align="middle"><h2>Additional Features</h2></div>

  <h3>Basic UI</h3>
  <p>We built the basic UI components necessary to load meshes from a template and insert additional meshes.</p>
  <h3>Drag and Drop</h3>
  <p>We added the ability to drag and drop meshes to allow for interaction with the scene. This feature will help demonstrate the live aspect of our project once we start calculating the light for each bounce.</p>
  <h3>Physics</h3>
  <p>We used <a href="http://brm.io/matter-js/">Matter.js</a>, which is a 2D physics engine. We integrated this physics engine with THREE.js. This allows us to run a physics world, that we can then rasterize onto the screen. So far, we have implemented two primitive types: rectangles and circles. We initialize our physics world in our init() function, and then at every render cycle we ask the physics engine for the new coordinates and rotation of all the shapes.</p>
  <p>
  <h3>2D Distance Fields</h3>
  <p>We initially attempted to calculate intersection points by raymarching across a signed distance field. However, we found that blind raymarching could not find intersections beyond the first, since the distance becomes stuck at zero. Due to the prohibitive cost of conditional branches in shaders, it was not possible to remove those meshes which the ray had already intersected.</p>
  <p>

  <div align="middle"><h1>Results</h1></div>

  <div align="middle"><h1>References</h1></div>
  <ul>
    <li>J. Hermes, N. Henrich, T. Grosch, and S. Mueller, "Global Illumination using Parallel Global Ray-Bundles," <i>Vision, Modeling, and Visualization</i>, 2010.</li>
    <li>J. Mortensen, P. Khanna, and M. Slater, "Light Field Propagation and Rendering on the GPU," The Association for Computing Machinery, 2007.</li>
    <li>T. Hachisuka, "High-Quality Global Illumination Rendering Using Rasterization," in <i>GPU Gems 2</i>, Matt Pharr, Ed., 2005.</li>
    <li>Y. Tokuyoshi, T. Sekine, and S. Ogaki, "Fast Global Illumination Baking via Ray-Bundles," THe Association for Computing Machinery, 2011.</li>
    <li>A. Thomsen and K. H. Nielsen, "Approximate Radiosity Using Stochastic Depth Buffering," Journal of Graphics, GPU, and Game Tools, 2011.</li>
    <li>The blog of Thomas Diewald</li>
    <li>The blog of Benedikt Bitterli</li>
  </ul>

  <div align="middle"><h1>Team Contributions</h1></div>

</div>

<br/>
<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/MathJax.js?config=TeX-MML-AM_CHTML' async></script>
</body>
</html>
