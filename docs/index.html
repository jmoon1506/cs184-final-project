<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head>
<style>
  body {
    padding: 100px;
    width: 1000px;
    margin: auto;
    text-align: left;
    font-weight: 300;
    font-family: 'Open Sans', sans-serif;
    color: #121212;
  }
  h1, h2, h3, h4 {
    font-family: 'Source Sans Pro', sans-serif;
  }
</style>
<title>CS 184 Mesh Editor</title>
<meta http-equiv="content-type" content="text/html; charset=utf-8" />
<link href="https://fonts.googleapis.com/css?family=Open+Sans|Source+Sans+Pro" rel="stylesheet">

</head>

<body>
<h1 align="middle">CS 184: Final Project, Spring 2018</h1>
<h1 align="middle">Real-time 2D Global Illumination</h1>
<h2 align="middle">Joseph Moon, Abdul AlZanki, Lawrence Elkins</h2>
<br/><br/>
<div>

<div align="left">
  <div align="middle">
    <h2>Title, Summary and Team Members</h2>
  </div>
		<p>For this project, we hope to implement an interactive 2D raytracer. We will start out by implementing a Monte Carlo raytracer similar to the one in Assignment 3 - with the ability to run in real-time. However, it would run at low-fidelity during scene changes. Our more ambitious goal is to create a parallel raytracer, which would have the ability to render billions of samples per second on consumer hardware and enable high-fidelity dynamic scenes.
			<br/><br/>
			Joseph Moon: 3033156362
			<br/><br/>
			Abdulrahman AlZenki: 25740621
			<br/><br/>
			Lawrence Elkins: 23452545
			<br/><br/>
		</p>

    <div align="middle">
      <h2>Problem Description</h2>
    </div>

		<p>Raytracing is a powerful method to generate realistic lighting effects, such as global illumination and soft shadows. It works by shooting rays into each screen pixel from the camera and approximating a solution to the rendering equation along each ray's intersections with the scene. An ongoing focus of research is raytracing in real-time, due to the algorithm's steep computational cost. We plan to mitigate this in several ways:</p>
		<ul>
			<li>Run the renderer in 2D space instead of 3D space to decrease complexity.</li>
			<li>When the camera or scene changes, we need to re-render the entire scene. To maintain real-time performance, we might render frames with just a few samples and gradually add new ones if the scene and camera stay still (i.e. lo-fi dynamic scenes).</li>
			<li>More ambitiously, we want to run raytracing on the GPU with a parallel ray-bundling algorithm to create hi-fi dynamic scenes.</li>
		</ul>

		<br/><br/>

    <div align="middle">
      <h2>Goals and Deliverables</h2>
    </div>
		<ul>
			<li>TODO: from spec: "Define how you will measure the quality / performance of your system (e.g. graphs showing speedup, or quantifying accuracy). It may not be possible to define precise target metrics at this time, but we encourage you to try."</li>
			<li>TODO: from spec: "What questions do you plan to answer with your analysis?"</li>
    </ul>

    <div align="left">
      <h3>What we plan to deliver: Real-time 2D Monte Carlo Path Tracing</h3>
    </div>
			<ul>
				<li>Render simple 2D scenes in real-time (limited number of lights and objects).</li>
				<li>To show that our renderer is in real-time, we will need to have the scene either be animating/changing in real-time or have the ability to interact with it.</li>
        <li>We will initially try the radiosity equation from class. If that doesn't work, then we will just deposit light along rays and adjust gamma (like in <a href="https://benedikt-bitterli.me/tantalum/tantalum.html">this resource</a>).</li>
				<li>In this implementation, we will sort of "lazy load" (TODO: Is this a good idea to refer to it as lazy loading, or do you think we shouldn't?) the scene after movements. This means that the quality of the real-time render might start out a bit noisy when things are first moved. For example: </li>

				<br/><br/>

				<div align="middle">
				  <table style="width=100%">
				    <tr>
				      <td>
				        <img src="images/pathtracer_low_samples.png" align="middle" width="300px"/>
				        <figcaption align="middle">How it looks when changing the scene</figcaption>
				      </td>
				      <td>
				        <img src="images/pathtracer_high_samples.png" align="middle" width="300px"/>
				        <figcaption align="middle">After staying still for several seconds</figcaption>
				      </td>
				    </tr>
				  </table>
				</div>
				<br/><br/>
        <li>Downsides</li>
        <ul>
          <li>Adjusting the camera or scene requires resampling the entire image, which is costly.</li>
          <li>Runs on CPU, or inefficiently on GPU</li>
          <li>Not truly real-time because of the quality of the rendering after movement. Impractical for actual applications</li>
          <li>Line deposition not physically-based, doesn't looks realistic unless we have a ridiculous number of samples</li>
        </ul>
        <li>Upsides</li>
        <ul>
          <li>Easier to render caustics and specular surfaces</li>
        </ul>
			</ul>
      <div align="left">
        <h3>What we hope to deliver: Real-time 2D Global Line Radiosity</h3>
      </div>
      <div align="middle">
        <table style="width=100%">
          <tr>
            <td>
              <img src="images/global_line_radiosity1.png" align="middle" width="300px"/>
              <figcaption align="middle">2D Global Line Radiosity</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br/><br/>
      <div align="middle">
        <table style="width=100%">
          <tr>
            <td>
              <img src="images/global_line_radiosity_direct.png" align="middle" width="300px"/>
              <figcaption align="middle">Only direct lighting</figcaption>
            </td>
            <td>
              <img src="images/global_line_radiosity_combined.png" align="middle" width="300px"/>
              <figcaption align="middle">Add indirect lighting</figcaption>
            </td>
          </tr>
        </table>
      </div>
      <br/><br/>
			<ul>
				<li>Parallel Ray-Bundling</li>
        <ul>
          <li>Each sample calculates radiosity equation at every pixel, but with rays all in the same direction.</li>
          <li>Sampling many times, with many solid angles, yields the equivalent result to raytracing.</li>
          <li>Essentially rasterizes with each sample, making better use of GPU than raytracing.</li>
        </ul>
        <br/><br/>
        <div align="middle">
          <table style="width=100%">
            <tr>
              <td>
                <img src="images/parallel_ray_bundling.png" align="middle" width="300px"/>
                <figcaption align="middle">Instead of raycasting randomly from different positions, we use bundles of parallel rays. Both methods yield the same result (Hachisuka 2005).</figcaption>
              </td>
              <td>
                <img src="images/parallel_ray_bundling2.png" align="middle" width="300px"/>
                <figcaption align="middle">Radiance is passed between intersection points.</figcaption>
              </td>
              <td>
                <img src="images/parallel_ray_bounce.png" align="middle" width="300px"/>
                <figcaption align="middle">Similar to traditional pathtracing, we can calculate bounces recursively.</figcaption>
              </td>
            </tr>
          </table>
        </div>
        <br/><br/>
        <li>If possible, we might use raymarching and distance functions instead of primitives and intersection tests.</li>
        <li>If possible, we might also use Cheap soft shadows, sub-surface scattering, ambient occlusion.</li>
        <br/><br/>
        <div align="middle">
          <table style="width=100%">
            <tr>
              <td>
                <img src="images/global_line_radiosity_sss.png" align="middle" width="600px"/>
                <figcaption align="middle">We can cheaply calculate lighting effects, such as sub-surface scattering</figcaption>
              </td>
            </tr>
          </table>
        </div>
        <br/><br/>
        <li>We think it will be possible to accomplish real-time global illumination because we have examples of people who have done so in our refrences. (TODO: this is not a good answer, expand on it).</li>
			</ul>
		<br/><br/>
    <div align="middle">
      <h2>TODO: Schedule</h2>
    </div>
    <p>In this section you should organize and plan the tasks and subtasks that your team will execute. Since presentations are ~4 weeks from the due-date of the proposal, you should include a set of tasks for every week.</p>

<br/><br/>

    <div align="middle">
      <h2>TODO: Resources</h2>
    </div>
		<ul>
			<li>List what resources, e.g. books, papers and/or online resources that are references for your project. List the computing platform, hardware and software resources that you will use for your project. You have a wide latitude here to use what you have access to, but be aware that you will have to support and trouble-shoot on your platform yourselves. If you are starting from an existing piece of code or system, describe and provide a pointer to it here.</li>
		</ul>
</div>

<!-- TODO:
I. 2D simplifications
  a. Only need to sample pixels on the 2D plane
  b. Only need to cast rays in 360 degrees, instead of an entire sphere
IV. Add related works
  > Monte Carlo pathtracer example: https://benedikt-bitterli.me/tantalum/tantalum.html
  > 2D Global Line Radiosity (currently down): http://thomasdiewald.com/blog/?p=2949
  > Papers (see references directory)
-->

</body>
</html>
